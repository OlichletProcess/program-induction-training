[
  {
    "objectID": "pyBPL/examples/fit_image.html",
    "href": "pyBPL/examples/fit_image.html",
    "title": "first, load the target image",
    "section": "",
    "text": "Code\nimport os\nimport cv2 # needed to create movie visualization of optimizaiton\n%matplotlib inline\nimport matplotlib.pylab as plt\nimport numpy as np\nfrom tqdm import tqdm\nimport imageio\nimport torch\nimport torch.distributions as dist\n\nfrom pybpl.library import Library\nfrom pybpl.model import CharacterModel\nfrom pybpl.objects.concept import CharacterType\nfrom pybpl.objects.part import StrokeType\nfrom pybpl.objects.relation import RelationIndependent, RelationAttachAlong\nfrom pybpl import rendering\nCode\n# library and type distribution\nlib = Library('../lib_data/')\nmodel = CharacterModel(lib)\nCode\n# for better image visualization in matplotlib\ndef box_only(obj):\n    obj.tick_params(\n        which='both',\n        bottom=False,\n        left=False,\n        labelbottom=False,\n        labelleft=False\n    )\nCode\nimg_target = imageio.imread('./image_H.jpg')\nimg_target = np.asarray(img_target, dtype=np.float32) / 255.\nplt.figure(figsize=(2,2))\nplt.imshow(img_target, cmap='Greys')\nbox_only(plt)\nplt.show()"
  },
  {
    "objectID": "pyBPL/examples/fit_image.html#now-create-an-initial-h-type-and-token-that-we-will-optimize",
    "href": "pyBPL/examples/fit_image.html#now-create-an-initial-h-type-and-token-that-we-will-optimize",
    "title": "first, load the target image",
    "section": "Now, create an initial “H” type and token that we will optimize",
    "text": "Now, create an initial “H” type and token that we will optimize\n\n\nCode\ndef initial_H_type():\n    # first stroke has 1 sub-stroke, with id \"0\"\n    s1 = StrokeType(\n        nsub=torch.tensor(1), \n        ids=torch.tensor([0]),\n        shapes=lib.shape['mu'][0].view(5, 2, 1),\n        invscales=torch.tensor([0.5])\n    )\n    r1 = RelationIndependent(\n        category='unihist',\n        #gpos=torch.tensor([30., -22.]),\n        gpos=torch.tensor([32., -20.]),\n        xlim=lib.Spatial.xlim,\n        ylim=lib.Spatial.ylim,\n    )\n    # second stroke has 1 sub-stroke, with id \"9\"\n    s2 = StrokeType(\n        nsub=torch.tensor(1), \n        ids=torch.tensor([9]),\n        shapes=lib.shape['mu'][9].view(5, 2, 1),\n        invscales=torch.tensor([0.4])\n    )\n    r2 = RelationAttachAlong(\n        category='mid',\n        attach_ix=torch.tensor(0),\n        attach_subix=torch.tensor(0),\n        eval_spot=torch.tensor(4.5),\n        ncpt=lib.ncpt\n    )\n    # third stroke has 1 sub-stroke, with id \"0\"\n    s3 = StrokeType(\n        nsub=torch.tensor(1), \n        ids=torch.tensor([0]),\n        shapes=lib.shape['mu'][0].view(5, 2, 1),\n        invscales=torch.tensor([0.5])\n    )\n    r3 = RelationIndependent(\n        category='unihist',\n        #gpos=torch.tensor([70., -22.]),\n        gpos=torch.tensor([68., -20.]),\n        xlim=lib.Spatial.xlim,\n        ylim=lib.Spatial.ylim\n    )\n    k = torch.tensor(3)\n    P = [s1, s2, s3]\n    R = [r1, r2, r3]\n    # initialize the type\n    ctype = CharacterType(k, P, R)\n    \n    return ctype\n\n\n\n\nCode\nctype = initial_H_type()\nctoken = model.sample_token(ctype)\n# get optimizable parameters\nparams = ctype.parameters() + ctoken.parameters()\nlbs = ctype.lbs() + ctoken.lbs()\nubs = ctype.ubs() + ctoken.ubs()\n# set requires_grad to True for asll parameters\nctype.train()\nctoken.train()\n\n\n\n\nCode\n# set large blur value to make learning easier\nctoken.blur_sigma = torch.tensor(\n    10., dtype=torch.float, requires_grad=True\n)\n\n\n\n\nCode\npimg = model.get_pimg(ctoken)\nplt.figure(figsize=(2,2))\nplt.imshow(pimg.detach().numpy(), cmap='Greys')\nbox_only(plt)\nplt.show()\n\n\n\n\n\n\n\n\n\n\noptimize\n\n\nCode\nvid = 'video.mov'\nif os.path.exists(vid):\n    os.remove(vid)\nvideo = cv2.VideoWriter(vid,-1,10,(105,105))\nnb_iter = 300\ninterval = 5 # how often we will log pimg status\nlr = 4e-3\nimg_target = torch.tensor(img_target)\n\nscore_type_list = []\nscore_token_list = []\nscore_img_list = []\noptimizer = torch.optim.Adam(params, lr=lr)\nfor idx in tqdm(range(nb_iter)):\n    if idx % interval == 0:\n        # store pimg at this iteration for later viewing\n        pimg = model.get_pimg(ctoken)\n        pimg = pimg.detach().numpy()\n        pimg = np.stack([pimg, pimg, pimg], axis=2)\n        pimg = np.asarray(pimg*255., dtype=np.uint8)\n        video.write(np.copy(pimg))\n    # compute scores\n    score_type = model.score_type(ctype)\n    score_token = model.score_token(ctype, ctoken)\n    score_img = model.score_image(ctoken, img_target)\n    score = score_type + score_token + score_img\n    # append to lists\n    score_type_list.append(score_type)\n    score_token_list.append(score_token)\n    score_img_list.append(score_img)\n    # first, zero all gradients\n    optimizer.zero_grad()\n    # now, perform backward pass\n    score_neg = -score\n    score_neg.backward()\n    # optimization step\n    optimizer.step()\n    # clip params at boundaries\n    with torch.no_grad():\n        for ip, param in enumerate(params):\n            lb = lbs[ip]\n            ub = ubs[ip]\n            if lb is not None:\n                torch.max(param, lb, out=param)\n            if ub is not None:\n                torch.min(param, ub, out=param)\n                \ncv2.destroyAllWindows()\nvideo.release()\n\n\n100%|██████████| 300/300 [00:16&lt;00:00, 18.38it/s]\n\n\n\n\ncheck loss vs iteration\n\n\nCode\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14,5))\n# type and token scores\naxes[0].plot(score_type_list, c='b', label='log P(type)')\naxes[0].plot(score_token_list, c='g', label='log P(token | type)')\naxes[0].set_ylabel('log-likelihood')\naxes[0].set_xlabel('iteration')\naxes[0].legend()\n# image score\naxes[1].plot(score_img_list, c='r', label='log P(image | token)')\naxes[1].set_ylabel('log-likelihood')\naxes[1].set_xlabel('iteration')\naxes[1].legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\ncheck pimg vs iteration\n\n\nCode\nplt.figure(figsize=(2,2))\nplt.imshow(img_target, cmap='Greys')\nbox_only(plt)\nplt.title('target')\nplt.show()\nprint('')\n\nfig, axes = plt.subplots(nrows=1, ncols=10, figsize=(15, 2))\nfor i in range(10):\n    axes[i].imshow(imgs[i], cmap='Greys')\n    box_only(axes[i])\n    axes[i].set_title('%i' % (interval*i))\nplt.show()"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Program Induction Practice",
    "section": "",
    "text": "Since I did not have any prior background in program induction, I wanted to gain an intuitive understanding of what processes it actually involves by coding it. To start, I looked for relevant materials and found the Science paper by Lake et al. (2015), in which the authors provided both data and source code. Below, I replicate and run several of their scripts to execute parts of the Bayesian Program Learning (BPL) process as an example of program induction. Because I currently do not have access to MATLAB, I only implemented the parts available in Python, so the full BPL pipeline was not reproduced.\n\n\nAccording to Rule et al. (2018), first of all, inductive programming refers to the “algorithms that learn program-like structures from obsevations,” which is a types of (or one of the fileds in) program synthesis. Program induction is, it seems like that, a process of concept learning which represents as programs that obtained from observed data. Now BPL seems to be a method of program induction, which I will try to replicate below. Its a generative process of a program with Bayesian methodology (Ellis et al., 2022), which authors states that “works by inferring a generative procedure represented as a symbolic program.”"
  },
  {
    "objectID": "index.html#what-is-program-induction",
    "href": "index.html#what-is-program-induction",
    "title": "Program Induction Practice",
    "section": "",
    "text": "According to Rule et al. (2018), first of all, inductive programming refers to the “algorithms that learn program-like structures from obsevations,” which is a types of (or one of the fileds in) program synthesis. Program induction is, it seems like that, a process of concept learning which represents as programs that obtained from observed data. Now BPL seems to be a method of program induction, which I will try to replicate below. Its a generative process of a program with Bayesian methodology (Ellis et al., 2022), which authors states that “works by inferring a generative procedure represented as a symbolic program.”"
  },
  {
    "objectID": "index.html#creating-omniglot",
    "href": "index.html#creating-omniglot",
    "title": "Program Induction Practice",
    "section": "1. Creating Omniglot",
    "text": "1. Creating Omniglot\nHere, following omniglot repository, I have replicated a visualization process using the dataset.\nThe Omniglot dataset provides both images and strokes data for handwritten characters.  By running codes shown below, each character is visualized as composition of multiple strokes.\nIt seems like this process is for visualizing compositional and generative nature of how each strokes and each characters are produced.\n\n\nCode\nimport numpy as np\nimport os\nimport random\nfrom sys import platform as sys_pf\nimport matplotlib\nif sys_pf == 'darwin':\n    matplotlib.use(\"TkAgg\")\nfrom matplotlib import pyplot as plt\n\ndef plot_motor_to_image(I,drawing,lw=2):\n    drawing = [d[:, 0:2] for d in drawing]\n    drawing = [space_motor_to_img(d) for d in drawing]\n    plt.imshow(I,cmap='gray')\n    ns = len(drawing)\n    for sid in range(ns):\n        plot_traj(drawing[sid],get_color(sid),lw)\n    plt.xticks([])\n    plt.yticks([])\n\ndef plot_traj(stk,color,lw):\n    n = stk.shape[0]\n    if n &gt; 1:\n        plt.plot(stk[:,0],stk[:,1],color=color,linewidth=lw)\n    else:\n        plt.plot(stk[0,0],stk[0,1],color=color,linewidth=lw,marker='.')\n\ndef get_color(k):\n    scol = ['r','g','b','m','c']\n    ncol = len(scol)\n    if k &lt; ncol:\n        out = scol[k]\n    else:\n        out = scol[-1]\n    return out\n\ndef num2str(idx):\n    if idx &lt; 10:\n        return '0'+str(idx)\n    return str(idx)\n\ndef load_img(fn):\n    I = plt.imread(fn)\n    I = np.array(I,dtype=bool)\n    return I\n\ndef load_motor(fn):\n    motor = []\n    with open(fn,'r') as fid:\n        lines = fid.readlines()\n    lines = [l.strip() for l in lines]\n    for myline in lines:\n        if myline =='START':\n            stk = []\n        elif myline =='BREAK':\n            stk = np.array(stk)\n            motor.append(stk)\n            stk = []\n        else:\n            arr = np.fromstring(myline,dtype=float,sep=',')\n            stk.append(arr)\n    return motor\n\ndef space_motor_to_img(pt):\n    pt[:,1] = -pt[:,1]\n    return pt\ndef space_img_to_motor(pt):\n    pt[:,1] = -pt[:,1]\n    return pt\n\nif __name__ == \"__main__\":\n    img_dir = 'images_background'\n    stroke_dir = 'strokes_background'\n    nreps = 20\n    nalpha = 5\n\n    alphabet_names = [a for a in os.listdir(img_dir) if a[0] != '.']\n    alphabet_names = random.sample(alphabet_names,nalpha)\n\n    for a in range(nalpha):\n        print('generating figure ' + str(a+1) + ' of ' + str(nalpha))\n        alpha_name = alphabet_names[a]\n\n        character_id = random.randint(1,len(os.listdir(os.path.join(img_dir,alpha_name))))\n\n        img_char_dir = os.path.join(img_dir,alpha_name,'character'+num2str(character_id))\n        stroke_char_dir = os.path.join(stroke_dir,alpha_name,'character'+num2str(character_id))\n\n        fn_example = os.listdir(img_char_dir)[0]\n        fn_base = fn_example[:fn_example.find('_')]\n\n        plt.figure(a,figsize=(6,5))\n        plt.clf()\n        for r in range(1,nreps+1):\n            plt.subplot(4,5,r)\n            fn_stk = stroke_char_dir + '/' + fn_base + '_' + num2str(r) + '.txt'\n            fn_img = img_char_dir + '/' + fn_base + '_' + num2str(r) + '.png'\n            motor = load_motor(fn_stk)\n            I = load_img(fn_img)\n            plot_motor_to_image(I,motor)\n            if r==1:\n                plt.title(alpha_name[:15] + '\\n character ' + str(character_id))\n        plt.tight_layout()\n    plt.show()\n\n\ngenerating figure 1 of 5\ngenerating figure 2 of 5\ngenerating figure 3 of 5\ngenerating figure 4 of 5\ngenerating figure 5 of 5"
  },
  {
    "objectID": "index.html#generating-bpl",
    "href": "index.html#generating-bpl",
    "title": "Program Induction Practice",
    "section": "2. generating BPL",
    "text": "2. generating BPL\nNow moving on, though only partially, to the actual BPL, i.e., program induction!\nIn implemeting this, I used the pyBPL library, a python version of the original MATLAB BPL model provided by Reuben Feinman.\nProbabilistic program of handwritten character is provided through this BPL. Below code loads pre-learned (on MATLAB) parameters, samples new character and “token,” then compute the log-likelihoods which is the likelihood that could potentially be used for posterior inference (something that is not covered by pyBPL).\n\n\nCode\nimport matplotlib.pyplot as plt\n\nfrom pyBPL.library.library import Library\nfrom pyBPL.model.model import CharacterModel\n\n\n\ndef display_type(c):\n    print(\"----BEGIN CHARACTER TYPE INFO----\")\n    print(\"num strokes: %i\" % c.k)\n    for i in range(c.k):\n        print(\"Stroke #%i:\" % i)\n        print(\"\\tsub-stroke ids: \", list(c.part_types[i].ids.numpy()))\n        print(\"\\trelation category: %s\" % c.relation_types[i].category)\n    print(\"----END CHARACTER TYPE INFO----\")\n\n\ndef main():\n    print(\"generating character...\")\n    lib = Library(use_hist=True)\n    model = CharacterModel(lib)\n    fig, axes = plt.subplots(nrows=10, ncols=5, figsize=(6, 15))\n    for i in range(10):\n        ctype = model.sample_type()\n        ll = model.score_type(ctype)\n        print(\"type %i\" % i)\n        display_type(ctype)\n        print(\"log-likelihood: %0.2f \\n\" % ll.item())\n        for j in range(5):\n            ctoken = model.sample_token(ctype)\n            img = model.sample_image(ctoken)\n            axes[i, j].imshow(img, cmap=\"Greys\")\n            axes[i, j].tick_params(\n                which=\"both\",\n                bottom=False,\n                left=False,\n                labelbottom=False,\n                labelleft=False,\n            )\n        axes[i, 0].set_ylabel(\"%i\" % i, fontsize=10)\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    main()\n\n\ngenerating character...\ntype 0\n----BEGIN CHARACTER TYPE INFO----\nnum strokes: 5\nStroke #0:\n    sub-stroke ids:  [255, 617, 665]\n    relation category: unihist\nStroke #1:\n    sub-stroke ids:  [41]\n    relation category: unihist\nStroke #2:\n    sub-stroke ids:  [1040]\n    relation category: mid\nStroke #3:\n    sub-stroke ids:  [139]\n    relation category: unihist\nStroke #4:\n    sub-stroke ids:  [1]\n    relation category: mid\n----END CHARACTER TYPE INFO----\nlog-likelihood: -264.84 \n\ntype 1\n----BEGIN CHARACTER TYPE INFO----\nnum strokes: 6\nStroke #0:\n    sub-stroke ids:  [18]\n    relation category: unihist\nStroke #1:\n    sub-stroke ids:  [2]\n    relation category: mid\nStroke #2:\n    sub-stroke ids:  [133]\n    relation category: mid\nStroke #3:\n    sub-stroke ids:  [716]\n    relation category: unihist\nStroke #4:\n    sub-stroke ids:  [17]\n    relation category: unihist\nStroke #5:\n    sub-stroke ids:  [433]\n    relation category: mid\n----END CHARACTER TYPE INFO----\nlog-likelihood: -218.35 \n\ntype 2\n----BEGIN CHARACTER TYPE INFO----\nnum strokes: 4\nStroke #0:\n    sub-stroke ids:  [2]\n    relation category: unihist\nStroke #1:\n    sub-stroke ids:  [11]\n    relation category: mid\nStroke #2:\n    sub-stroke ids:  [483]\n    relation category: mid\nStroke #3:\n    sub-stroke ids:  [401]\n    relation category: mid\n----END CHARACTER TYPE INFO----\nlog-likelihood: -132.89 \n\ntype 3\n----BEGIN CHARACTER TYPE INFO----\nnum strokes: 3\nStroke #0:\n    sub-stroke ids:  [595]\n    relation category: unihist\nStroke #1:\n    sub-stroke ids:  [6, 488, 308]\n    relation category: end\nStroke #2:\n    sub-stroke ids:  [383]\n    relation category: mid\n----END CHARACTER TYPE INFO----\nlog-likelihood: -190.17 \n\ntype 4\n----BEGIN CHARACTER TYPE INFO----\nnum strokes: 4\nStroke #0:\n    sub-stroke ids:  [141]\n    relation category: unihist\nStroke #1:\n    sub-stroke ids:  [88]\n    relation category: start\nStroke #2:\n    sub-stroke ids:  [83]\n    relation category: mid\nStroke #3:\n    sub-stroke ids:  [653, 1126]\n    relation category: unihist\n----END CHARACTER TYPE INFO----\nlog-likelihood: -194.31 \n\n\n\ntype 5\n----BEGIN CHARACTER TYPE INFO----\nnum strokes: 2\nStroke #0:\n    sub-stroke ids:  [16, 1]\n    relation category: unihist\nStroke #1:\n    sub-stroke ids:  [980, 567]\n    relation category: mid\n----END CHARACTER TYPE INFO----\nlog-likelihood: -131.33 \n\ntype 6\n----BEGIN CHARACTER TYPE INFO----\nnum strokes: 2\nStroke #0:\n    sub-stroke ids:  [91]\n    relation category: unihist\nStroke #1:\n    sub-stroke ids:  [8]\n    relation category: mid\n----END CHARACTER TYPE INFO----\nlog-likelihood: -57.14 \n\ntype 7\n----BEGIN CHARACTER TYPE INFO----\nnum strokes: 3\nStroke #0:\n    sub-stroke ids:  [196]\n    relation category: unihist\nStroke #1:\n    sub-stroke ids:  [390]\n    relation category: mid\nStroke #2:\n    sub-stroke ids:  [552]\n    relation category: mid\n----END CHARACTER TYPE INFO----\nlog-likelihood: -118.78 \n\ntype 8\n----BEGIN CHARACTER TYPE INFO----\nnum strokes: 2\nStroke #0:\n    sub-stroke ids:  [1]\n    relation category: unihist\nStroke #1:\n    sub-stroke ids:  [384, 655, 233, 842, 611, 623, 744]\n    relation category: end\n----END CHARACTER TYPE INFO----\nlog-likelihood: -288.61 \n\ntype 9\n----BEGIN CHARACTER TYPE INFO----\nnum strokes: 2\nStroke #0:\n    sub-stroke ids:  [46, 15, 19]\n    relation category: unihist\nStroke #1:\n    sub-stroke ids:  [251]\n    relation category: mid\n----END CHARACTER TYPE INFO----\nlog-likelihood: -127.23 \n\n\n\n\n\n\n\n\n\n\nLog-likelihood of each generative model is provided with the figure.\nThrough this coding replication exercise, I was able to grasp how observed data (e.g., handwritten characters, language, objects) can be represented as structured, compositional programs. Visualizing these process helped me appreciate how compositionality function in human cognition. I am interested in how compositional knowledge structes can be entailed into program induction frameworks!"
  }
]